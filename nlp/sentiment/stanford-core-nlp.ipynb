{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford CoreNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation notes taken from here: https://stackoverflow.com/questions/32879532/stanford-nlp-for-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Stanford CoreNLP\n",
    "The latest version at this time (2018-02-27) is 3.9.1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "wget http://nlp.stanford.edu/software/stanford-corenlp-full-2018-02-27.zip\n",
    "unzip stanford-corenlp-full-2018-02-27.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd stanford-corenlp-full-2018-02-27\n",
    "java -mx5g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -timeout 10000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* timeout is in milliseconds, I set it to 10 sec above. You should increase it if you pass huge blobs to the server.\n",
    "* There are more options, you can list them with --help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You pass the whole text to the server and it splits it into sentences.\n",
    "2. The sentiment is ascribed to each sentence, not the whole text.\n",
    "3. The average sentiment of text is between `Positive (3)`, `Neutral (2)` and `Negative (1)`, the range is from `VeryNegative (0)` to `VeryPositive (4)` which appear to be quite rare.\n",
    "4. You can stop the server either by typing `Ctrl-C` at the terminal you started it from or using the shell command `kill $(lsof -ti tcp:9000)`. `9000` is the default port, you can change it using the `-port` option when starting the server.\n",
    "5. Increase timeout (in milliseconds) in server or client if you get timeout errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python packages list available here: https://stanfordnlp.github.io/CoreNLP/other-languages.html#python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pip install pycorenlp\n",
    "pip install stanfordcorenlp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCoreNLP Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: https://github.com/smilli/py-corenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 'I love you .': 3 Positive\n",
      "1: 'I hate him .': 1 Negative\n",
      "2: 'You are nice .': 3 Positive\n",
      "3: 'He is dumb .': 1 Negative\n"
     ]
    }
   ],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "res = nlp.annotate(\"I love you. I hate him. You are nice. He is dumb.\",\n",
    "                   properties={\n",
    "                       'annotators': 'sentiment',\n",
    "                       'outputFormat': 'json',\n",
    "                       'timeout': 1000,\n",
    "                   })\n",
    "#print(type(res)) # <class 'dict'>\n",
    "\n",
    "for s in res[\"sentences\"]:\n",
    "    print(\"%d: '%s': %s %s\" % (\n",
    "        s[\"index\"],\n",
    "        \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
    "        s[\"sentimentValue\"], s[\"sentiment\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StanfordCoreNLP Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: https://github.com/Lynten/stanford-corenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 'This World is an amazing place .': 4 Verypositive\n"
     ]
    }
   ],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import json\n",
    "\n",
    "nlp = StanfordCoreNLP(r'http://localhost', port=9000)\n",
    "\n",
    "sentence = 'This World is an amazing place.'\n",
    "properties = {'annotators': 'sentiment', \n",
    "              'pinelineLanguage': 'en', \n",
    "              'outputFormat': 'json'}\n",
    "res = nlp.annotate(sentence, properties = properties)\n",
    "\n",
    "#print(res) # <class 'str'>\n",
    "res = json.loads(res)\n",
    "\n",
    "for s in res[\"sentences\"]:\n",
    "    print(\"%d: '%s': %s %s\" % (\n",
    "        s[\"index\"],\n",
    "        \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
    "        s[\"sentimentValue\"], s[\"sentiment\"]))\n",
    "\n",
    "nlp.close() # Do not forget to close! The backend server will consume a lot memery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available languages: https://stanfordnlp.github.io/CoreNLP/download.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "cd stanford-corenlp-full-2018-02-27\n",
    "wget http://nlp.stanford.edu/software/stanford-arabic-corenlp-2018-02-27-models.jar\n",
    "wget http://nlp.stanford.edu/software/stanford-chinese-corenlp-2018-02-27-models.jar\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: '這個世界是一個了不起的地方 。': 2 Neutral\n"
     ]
    }
   ],
   "source": [
    "# _*_coding:utf-8_*_\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import json\n",
    "\n",
    "nlp = StanfordCoreNLP(r'http://localhost', port=9000, lang='zh')\n",
    "\n",
    "#sentence = '这个世界是一个了不起的地方。' #simplified, This World is an amazing place.\n",
    "sentence = '這個世界是一個了不起的地方。' #traditional, This World is an amazing place.\n",
    "properties = {'annotators': 'sentiment', \n",
    "              'pinelineLanguage': 'zh', \n",
    "              'outputFormat': 'json'}\n",
    "res = nlp.annotate(sentence, properties = properties)\n",
    "res = json.loads(res)\n",
    "\n",
    "for s in res[\"sentences\"]:\n",
    "    print(\"%d: '%s': %s %s\" % (\n",
    "        s[\"index\"],\n",
    "        \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
    "        s[\"sentimentValue\"], s[\"sentiment\"]))\n",
    "\n",
    "nlp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['這個世界是一個了不起的地方', '。']\n",
      "[('這個世界是一個了不起的地方', 'NN'), ('。', 'SYM')]\n",
      "[('這個世界是一個了不起的地方', 'O'), ('。', 'O')]\n",
      "(ROOT\n",
      "  (NP (NN 這個世界是一個了不起的地方) (SYM 。)))\n",
      "[('ROOT', 0, 1), ('dep', 1, 2)]\n"
     ]
    }
   ],
   "source": [
    "# _*_coding:utf-8_*_\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import json\n",
    "\n",
    "# Other human languages support, e.g. Chinese\n",
    "sentence = '這個世界是一個了不起的地方。'\n",
    "\n",
    "with StanfordCoreNLP(r'http://localhost', port=9000, lang='zh') as nlp:\n",
    "    print(nlp.word_tokenize(sentence))\n",
    "    print(nlp.pos_tag(sentence))\n",
    "    print(nlp.ner(sentence))\n",
    "    print(nlp.parse(sentence))\n",
    "    print(nlp.dependency_parse(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 'أحبك .': 2 Neutral\n",
      "1: 'أنا أكرهه .': 2 Neutral\n",
      "2: 'أنت لطيف .': 2 Neutral\n",
      "3: 'إنه غبي': 2 Neutral\n"
     ]
    }
   ],
   "source": [
    "# _*_coding:utf-8_*_\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import json\n",
    "\n",
    "nlp = StanfordCoreNLP(r'http://localhost', port=9000, lang='ar')\n",
    "\n",
    "sentence = 'أحبك. أنا أكرهه. أنت لطيف. إنه غبي' #I love you. I hate him. you are kind. Stupid\n",
    "properties = {'annotators': 'sentiment', \n",
    "              'pinelineLanguage': 'ar', \n",
    "              'outputFormat': 'json'}\n",
    "res = nlp.annotate(sentence, properties = properties)\n",
    "res = json.loads(res)\n",
    "\n",
    "for s in res[\"sentences\"]:\n",
    "    print(\"%d: '%s': %s %s\" % (\n",
    "        s[\"index\"],\n",
    "        \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
    "        s[\"sentimentValue\"], s[\"sentiment\"]))\n",
    "\n",
    "nlp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
