{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is linguistic approach how to extract keywords from the sentence. It's not always 100% accurate, since there are unobserved words (specific named entities), but that's happening also for machine learning approach. Anyway, the advantage of this approach is to unnecessity of training set as it is necessary in case of usage supervised machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load model (https://spacy.io/models) which Spacy team maintain for Spacy usage. In this case it's English corpus (https://spacy.io/models/en) small version (35 MB) covering enough Part-of-Speech of accuracy (97.04%) and Named Entity Recognition accuracy (~ 85%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "df = pd.read_csv('questions_or_not.txt', sep = '\\t', names = ['question_expected','text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of the keywords is done in two steps:\n",
    "- Named Entity Recognition (NER, see https://spacy.io/api/annotation#section-named-entities)\n",
    "- Part-of-Speech Tags (PoS, see https://spacy.io/api/annotation#section-pos-tagging) specifically:\n",
    "    - Syntactic Dependency Tags defined by `dep_` attribute on the object\n",
    "        - dobj = direct object\n",
    "        - pobj = object of preposition\n",
    "        - conj = conjunct\n",
    "        - compound = compound\n",
    "    - The Universal Part-of-speech Tags defined by `pos_` attribute on the object\n",
    "        - NOUN = noun\n",
    "    - The English Part-of-speech Tags defined by `tag_` attribute on the object\n",
    "        - WP = wh-pronoun, personal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "for index, row in df.iterrows():\n",
    "    kw = []\n",
    "    parsed_text = nlp(row['text'])\n",
    "    # taking all named entities as keywords\n",
    "    for entity in parsed_text.ents:\n",
    "        #kw.append(\"%s(%s)\" % (entity.text, entity.label_))\n",
    "        kw.append(entity.text)\n",
    "    for pt in parsed_text:\n",
    "        # taking just part of speech tags as keywords\n",
    "        if pt.dep_ in ('pobj', 'dobj', 'conj', 'compound') and pt.pos_ in ('NOUN') and pt.tag_ not in ('WP'):\n",
    "            #kw.append(\"%s(%s,%s)\"%(pt, pt.pos_, pt.tag_)) \n",
    "            kw.append(str(pt)) \n",
    "    # make the list of keyword unique when name entities and objects makes duplicity\n",
    "    kw = list(set(kw))\n",
    "    keywords.append(', '.join(str(k) for k in kw))\n",
    "df = df.assign(keywords=keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wh-pronoun, personal'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"WP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result is then tabulated as the original text and the keywords extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anyone knows of a list of Kylo users that we can show as references?</td>\n",
       "      <td>Kylo, list, users, references</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I know of Coke and Lego, but a largest list will help. Thanks!</td>\n",
       "      <td>Coke, Lego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do we have any use cases where we have utilised 3D visualisation technology?</td>\n",
       "      <td>use, technology, visualisation, cases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does someone have more information, decks of the new TD which was presented in partners?</td>\n",
       "      <td>partners, information, TD, decks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do we have any material on internal fraud on banking?</td>\n",
       "      <td>material, banking, fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Any assessment or implementation on this front?</td>\n",
       "      <td>implementation, front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I am looking for pre-sale information for Data Science Lab.</td>\n",
       "      <td>sale, information, Data Science Lab, Lab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Is there someone who has experience within Projects with the Next-Gen Data Platform or Converged Data Platform from MapR?</td>\n",
       "      <td>experience, Converged Data Platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I've been preparing for a TD AppCenter demo for a customer and created a set of demo videos for backup.</td>\n",
       "      <td>backup, set, videos, customer, TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>These may be useful for ones who want to learn about it.</td>\n",
       "      <td>ones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Can someone point me to the mobile phone setup instructions?</td>\n",
       "      <td>instructions, setup, phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Could you please share real deployed cases about Kylo which i can show to my customer?</td>\n",
       "      <td>Kylo, customer, cases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Or give me please contacts who can help me.</td>\n",
       "      <td>contacts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>So if I were to sell the Analytic Ops accelerator we announced at partners, where would the assets be found, and who is the owner of these?</td>\n",
       "      <td>Analytic Ops, partners, accelerator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I am trying to collate different Image Processing use cases for a government customer.</td>\n",
       "      <td>use, cases, Image Processing, government, customer, Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Is there a place where I can find different use cases such as OCR, face detection/recognition, unattended baggage detection etc.?</td>\n",
       "      <td>use, cases, baggage, OCR, detection, recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Paul Huibers did a great job at Cleveland Clinic this week demonstrating the power of AI in healthcare!</td>\n",
       "      <td>Paul Huibers, Cleveland Clinic, job, power, this week, healthcare, AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Does anyone know if we have some discounts on Cloudera certifications negotiated at the moment?</td>\n",
       "      <td>Cloudera, certifications, discounts, moment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Not sure if you guys in London are aware about this interesting conference next week.</td>\n",
       "      <td>London, conference, next week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Do we have any references on using Kudu?</td>\n",
       "      <td>Kudu, references</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>We had an opportunity and could use some advice.</td>\n",
       "      <td>advice, opportunity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Does anyone have a copy of the excellent HBase presentation that Bryce Cottam did a few years ago for a Think Big bootcamp?</td>\n",
       "      <td>a few years ago, bootcamp, Bryce Cottam, copy, presentation, HBase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Posting some pictures from the Diwali Celebrations at one of our Client Williams Sonoma in San Francisco....Enjoy!!!!</td>\n",
       "      <td>one, pictures, San Francisco, Williams Sonoma, the Diwali Celebrations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Using data from Kaggle ML and Data Science Survey, 2017</td>\n",
       "      <td>Data Science Survey, 2017, Kaggle, data, ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The lesson of the day, order less Mexican food than you think you will need.</td>\n",
       "      <td>day, the day, food, Mexican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           text  \\\n",
       "0   Anyone knows of a list of Kylo users that we can show as references?                                                                          \n",
       "1   I know of Coke and Lego, but a largest list will help. Thanks!                                                                                \n",
       "2   Do we have any use cases where we have utilised 3D visualisation technology?                                                                  \n",
       "3   Does someone have more information, decks of the new TD which was presented in partners?                                                      \n",
       "4   Do we have any material on internal fraud on banking?                                                                                         \n",
       "5   Any assessment or implementation on this front?                                                                                               \n",
       "6   I am looking for pre-sale information for Data Science Lab.                                                                                   \n",
       "7   Is there someone who has experience within Projects with the Next-Gen Data Platform or Converged Data Platform from MapR?                     \n",
       "8   I've been preparing for a TD AppCenter demo for a customer and created a set of demo videos for backup.                                       \n",
       "9   These may be useful for ones who want to learn about it.                                                                                      \n",
       "10  Can someone point me to the mobile phone setup instructions?                                                                                  \n",
       "11  Could you please share real deployed cases about Kylo which i can show to my customer?                                                        \n",
       "12  Or give me please contacts who can help me.                                                                                                   \n",
       "13  So if I were to sell the Analytic Ops accelerator we announced at partners, where would the assets be found, and who is the owner of these?   \n",
       "14  I am trying to collate different Image Processing use cases for a government customer.                                                        \n",
       "15  Is there a place where I can find different use cases such as OCR, face detection/recognition, unattended baggage detection etc.?             \n",
       "16  Paul Huibers did a great job at Cleveland Clinic this week demonstrating the power of AI in healthcare!                                       \n",
       "17  Does anyone know if we have some discounts on Cloudera certifications negotiated at the moment?                                               \n",
       "18  Not sure if you guys in London are aware about this interesting conference next week.                                                         \n",
       "19  Do we have any references on using Kudu?                                                                                                      \n",
       "20  We had an opportunity and could use some advice.                                                                                              \n",
       "21  Does anyone have a copy of the excellent HBase presentation that Bryce Cottam did a few years ago for a Think Big bootcamp?                   \n",
       "22  Posting some pictures from the Diwali Celebrations at one of our Client Williams Sonoma in San Francisco....Enjoy!!!!                         \n",
       "23  Using data from Kaggle ML and Data Science Survey, 2017                                                                                       \n",
       "24  The lesson of the day, order less Mexican food than you think you will need.                                                                  \n",
       "\n",
       "                                                                  keywords  \n",
       "0   Kylo, list, users, references                                           \n",
       "1   Coke, Lego                                                              \n",
       "2   use, technology, visualisation, cases                                   \n",
       "3   partners, information, TD, decks                                        \n",
       "4   material, banking, fraud                                                \n",
       "5   implementation, front                                                   \n",
       "6   sale, information, Data Science Lab, Lab                                \n",
       "7   experience, Converged Data Platform                                     \n",
       "8   backup, set, videos, customer, TD                                       \n",
       "9   ones                                                                    \n",
       "10  instructions, setup, phone                                              \n",
       "11  Kylo, customer, cases                                                   \n",
       "12  contacts                                                                \n",
       "13  Analytic Ops, partners, accelerator                                     \n",
       "14  use, cases, Image Processing, government, customer, Processing          \n",
       "15  use, cases, baggage, OCR, detection, recognition                        \n",
       "16  Paul Huibers, Cleveland Clinic, job, power, this week, healthcare, AI   \n",
       "17  Cloudera, certifications, discounts, moment                             \n",
       "18  London, conference, next week                                           \n",
       "19  Kudu, references                                                        \n",
       "20  advice, opportunity                                                     \n",
       "21  a few years ago, bootcamp, Bryce Cottam, copy, presentation, HBase      \n",
       "22  one, pictures, San Francisco, Williams Sonoma, the Diwali Celebrations  \n",
       "23  Data Science Survey, 2017, Kaggle, data, ML                             \n",
       "24  day, the day, food, Mexican                                             "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"text\",\"keywords\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
